# Anycall Frontend

<img width="921" height="649" alt="스크린샷 2026-01-13 오후 5 59 45" src="https://github.com/user-attachments/assets/2ee81aaa-4c09-40e7-8484-66002eaa7230" />


# 📞 산학프로젝트: Anycall

> **팀명**: 컴공으로 앞서강  
> **담당 교수**: 정영민 교수님  
> **팀원**: 20211558 윤준서, 20211506 김도영, 20211561 이규형, 20211576 이준수

---

## 📑 목차
1. [개요](#1-개요)
    - [1-1. 프로젝트 소개](#1-1-프로젝트-소개)
    - [1-2. 추진 배경 및 필요성](#1-2-추진-배경-및-필요성)
    - [1-3. 핵심 가치](#1-3-핵심-가치)
    - [1-4. 프로젝트 목표](#1-4-프로젝트-목표)
    - [1-5. 프로젝트 독창성](#1-5-프로젝트-독창성)
2. [개발 내용](#2-개발-내용)
    - [2-1. 전체 프로그램 구조도](#2-1-전체-프로그램-구조도)
    - [2-2. 설계 주요 고려사항](#2-2-설계-주요-고려사항)
    - [2-3. 개발 항목](#2-3-개발-항목)
    - [2-4. 이슈 및 해결방안](#2-4-이슈-및-해결방안)
3. [성과](#3-성과)
4. [검증](#4-검증)
5. [향후 발전 방향](#5-향후-발전-방향)
    - [5-1. 서비스 확장 가능성](#5-1-서비스-확장-가능성)
    - [5-2. 고도화 로드맵](#5-2-고도화-로드맵)
    - [5-3. 잠재적 사업화 방향](#5-3-잠재적-사업화-방향)

---

## 1. 개요

### 1-1. 프로젝트 소개
Anycall은 AI 음성 모델과 대화형 LLM을 기반으로, 시니어 사용자가 복잡한 조작 없이 자연스러운 음성 대화를 이어갈 수 있도록 설계된 가상 통화 서비스입니다. 특히 고령층·사회적 취약계층을 대상으로 실제 전화와 유사한 경험을 제공하는 것을 핵심 목표로 하며, 기존의 음성 기반 AI 서비스가 가진 접근성 문제를 개선합니다.

### 1-2. 추진 배경 및 필요성
현재 상용화된 대화형 AI 서비스는 UI 복잡성, 낮은 시니어 친화성, 지속적인 맥락 유지의 어려움 등으로 인해 고령층 사용자 만족도가 낮다는 문제가 있습니다. Anycall은 이러한 불편을 해소하기 위해 '통화 시작' 버튼만으로 바로 대화가 가능한 간단한 구조를 채택하고, Whisper 기반 STT·대규모 언어 모델·특정 인물 기반 TTS를 결합해 실제 전화에 가까운 상호작용 흐름을 구현합니다.

### 1-3. 핵심 가치
사용자의 계정을 기반으로 이전 대화 맥락을 기억하고 이어갈 수 있도록 설계함으로써 단순 질의응답을 넘어 지속적인 관계 형성과 감정적 안정 제공을 목표로 합니다. 이는 돌아가신 배우자나 가족의 목소리로 대화하고 싶은 고령층 심리적 니즈를 반영한 서비스 방향성과, 개인화된 음성 모델 기술의 발전이 맞물린 결과입니다.

### 1-4. 프로젝트 목표
Anycall은 일상 대화뿐 아니라 병원 예약, 생활 정보 안내, 120 상담 연계와 같은 공공 서비스 보완 역할까지 수행할 수 있도록 확장성을 갖추고 있습니다. 궁극적으로는 시니어가 일상에서 가장 익숙하게 사용하는 '전화'라는 인터페이스를 중심으로, AI 기반의 정서적 안정, 정보 접근성, 사용 편의성을 동시에 충족하는 지속 가능한 소통 플랫폼을 구축하는 것을 지향합니다.

### 1-5. 프로젝트 독창성
Anycall은 고령층 사용자 중심의 음성 기반 상호작용을 핵심으로 삼아, 기존의 AI 대화 서비스가 제공하지 못했던 정서적 안정·지속적 관계·개인화 음성 경험을 통합적으로 구현했다는 점에 있습니다. 단순히 음성으로 응답하는 챗봇 수준을 넘어, 주변 인물의 목소리를 사용하여 안정감을 높였습니다. 또한 실제 전화와 동일한 UX·UI를 제공함으로써 시니어 계층이 일상적으로 사용할 수 있는 현실적인 접근을 채택했습니다.

## 2. 개발 내용

### 2-1. 전체 프로그램 구조도
</br>Anycall 서비스 음성 처리 흐름
* 1. [사용자 음성 입력]
* 2. [잡음 제거 + 음성 인식(STT)]
</br>– Whisper / Faster-Whisper / Whisper-Turbo
</br>– Google Speech API
* 3. [대화 생성 엔진(LLM)]
</br>– GPT-4, Gemini, KoGPT
* 4. [음성 합성(TTS)]
</br>– ElevenLabs
</br>– 커스텀 개인화 음성 모델
* 5. [모바일 앱 처리]
</br>– Android Studio(Kotlin), Xcode 기반 실시간 재생
* 6. [백엔드 및 데이터베이스]
</br>– FastAPI 기반 실시간 통신 처리
</br>– MongoDB / Firebase 저장 구조
* 7. [맥락 기억 모듈]
</br>– Session Manager 기반 대화 맥락 저장 및 활용

### 2-2. 설계 주요 고려사항
Anycall의 음성 처리 흐름은 사용자의 발화가 입력되는 순간부터 응답이 생성되어 다시 음성으로 전달되는 과정까지 일련의 단계로 구성되었습니다. 사용자가 말한 음성은 먼저 Whisper나 Google Speech API를 통해 잡음 제거와 함께 텍스트로 변환되고, 이 텍스트는 GPT-4, Gemini, KoGPT와 같은 대화 엔진에서 문맥을 고려하여 적절한 응답을 생성합니다.
</br>생성된 문장은 CLOVA Voice, ElevenLabs 또는 사용자가 직접 설정한 개인화 음성 모델을 이용해 자연스러운 음성으로 변환되었습니다. 변환된 음성은 Android Studio나 Xcode로 구현된 모바일 앱 화면에서 바로 재생되며, 전체 과정은 FastAPI 기반 서버와 MongoDB·Firebase 데이터베이스를 중심으로 실시간으로 처리됩니다.
</br>또한 긴 대화 흐름을 유지하기 위해 Session Manager가 맥락을 저장하고, 필요할 경우 120 상담 안내 모듈이 연동되는 구조로 설계되었습니다. 120 안내 연동은 테스트 중 호출 가능성에 대비해, 프론트엔드 차원에서만 구현했습니다.

### 2-3. 개발 항목
* **2-3-1. STT-LLM-TTS 음성 파이프라인**
</br>전체 음성 파이프라인은 0.5초 이내 STT와 0.8초 이내 TTS 생성을 목표로 설계되었습니다. 한국어 특성을 반영해 Whisper v3를 한국어 데이터로 추가 학습하여 WER을 약 15% 개선하고 방언 대응력을 높였습니다.
</br>또한 VAD 기반 스트리밍 세그멘테이션을 적용해 발화 종료 후 약 0.3-0.5초 내 STT 결과를 반환하도록 하여 지연을 크게 줄였습니다. TTS는 문장 단위로 즉시 생성하는 스트리밍 방식을 도입해 3-5초의 대기 시간을 제거하고 0.3-0.8초 수준의 빠른 응답을 구현했습니다. 이러한 최적화를 통해 실시간 통화 환경에서도 끊김 없는 자연스러운 상호작용이 가능해졌습니다.

* **2-3-2. 대화 엔진 및 맥락 기억 구조**
</br>대화 엔진은 STT와 TTS 사이에서 사용자의 의도와 감정을 분석하고 자연스러운 응답을 생성하는 핵심 모듈로, 대화 맥락을 지속적으로 유지하도록 설계되었습니다. STT 텍스트와 이전 발화 기록을 함께 분석하여 문맥 기반 응답을 생성하며, LLM을 활용해 긴 대화 흐름과 사용자 말투·선호를 반영할 수 있도록 했습니다.
</br>또한 사용자 계정 단위로 대화 로그를 저장해 이전 주제를 이어가는 맥락 기반 대화가 가능하도록 구현했습니다. 상황별 프롬프트 템플릿을 적용해 이해하기 쉬운 표현을 사용하도록 했고, 응답 길이와 어투를 자동 조절하는 후처리와 필터링을 통해 안정적이고 신뢰성 있는 대화를 제공하도록 했습니다.

* **2-3-3. 모바일 앱(UI/UX 및 기능 흐름)**
</br>모바일 애플리케이션은 시니어 사용자가 복잡한 조작 없이 AI와 바로 대화할 수 있도록 단순한 UI로 설계되었습니다. 앱 실행 시 ‘통화 시작’ 버튼만으로 즉시 연결되며, 통화 화면에는 상태 표시와 종료 버튼만 배치해 불필요한 요소를 제거했습니다.
</br>음성은 WebSocket 기반 스트리밍 구조로 송수신되어, 사용자의 발화 직후 AI 응답이 자연스럽게 재생되도록 지연을 최소화했습니다. 또한 큰 글씨, 높은 대비 색상, 직관적인 버튼 배치를 적용해 실제 전화 통화와 유사한 간편한 사용 경험을 제공했습니다.

* **2-3-4. 실시간 통신 기반 백엔드 아키텍처**
</br>백엔드 시스템은 STT–LLM–TTS 파이프라인이 지연 없이 동작하도록 낮은 지연과 높은 처리량을 동시에 충족하는 구조로 설계되었습니다. 핵심은 비동기 WebSocket 기반의 Non-Blocking I/O 통신으로, 대규모 동시 연결에서도 안정적인 실시간 음성 스트리밍이 가능하도록 구현했습니다.
</br>또한 문자열 기반 프로토콜 대신 순수 이진데이터 전송 방식을 사용해 직렬화·파싱 비용과 네트워크 오버헤드를 최소화했으며, 1바이트 인덱스 프로토콜을 도입해 데이터 유형을 즉시 구분하도록 했습니다. 이를 통해 지연 시간을 크게 줄이고, 실제 통화 환경에서도 끊김 없는 상호작용과 높은 성능·확장성을 확보했습니다.

### 2-4. 이슈 및 해결방안
* **2-4-1. 기술적 리스크**
* **2-4-2. 데이터·모델·UX 관련 리스크**

## 3. 성과
* **3-1. 기능·성능 목표 및 목표 대비 성과**
* **3-2. 프로젝트 산출물**
* **3-3. 산출물 목록**
* **3-4. 멘토 평가 의견**

## 4. 검증
* **4-1. 테스트 계획 및 기준**
* **4-2. 테스트 결과 및 분석**

## 5. 향후 발전 방향

### 5-1. 서비스 확장 가능성
병원 예약, 복지 상담, 지역 행정 안내 등 공공 서비스 연계 기능을 강화할 경우 공공기관의 정보 전달 부담을 줄이는 보조 서비스로 자리잡을 수 있습니다. 
특히 120 다산콜센터, 보건소 등과의 API 연계를 확대한다면 시니어에게 실질적인 편의를 제공하는 중요한 서비스로 발전될 수 있습니다.

### 5-2. 고도화 로드맵
향후 서비스 고도화는 음성 파이프라인의 품질 향상과 사용자 경험 개선, 개인화 기능 확장, 그리고 보안·윤리 체계 강화 등을 중심으로 진행될 계획입니다.
* **음성 파이프라인**: Whisper 기반 STT의 환경 적응력을 높이고, TTS 음색의 자연스러움을 정교하게 다듬을 예정입니다.
* **LLM**: 문맥 유지 능력을 강화하여 실제 통화에 가까운 자연스러운 상호작용을 가능하게 합니다.
* **UX 강화**: 사용자 피드백을 반영해 버튼 배치, 화면 전환 속도, 글자 크기 등을 재검토하여 학습 없이 사용할 수 있는 환경을 목표로 합니다.
* **개인화 확장**: 감정 톤 조절, 말투 변화, 대화 스타일 맞춤화 기능 등을 고도화하여 정서적 안정과 친숙함을 강화할 예정입니다.

### 5-3. 잠재적 사업화 방향
시니어 돌봄 시장을 중심으로 B2C 서비스 모델로 확장될 수 있습니다. 1인 가구 증가와 고령화 심화로 인해 정서적·정보적 지원에 대한 수요가 꾸준히 증가하고 있어, 서비스 가입 기반의 모델로 안정적으로 운영될 수 있는 가능성이 있습니다.
